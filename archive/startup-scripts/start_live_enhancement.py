#!/usr/bin/env python3
"""
Live AI Enhancement for Minimal Container
Phase 23: Real-time AI integration without container rebuild
Demonstrates incremental enhancement using existing minimal dependencies
"""

import os
import sys
import uvicorn
from pathlib import Path

# Add project paths
sys.path.append('.')
sys.path.append('./src')

# Set environment variables for live enhancement
os.environ['LUCIQ_LIVE_ENHANCEMENT'] = 'true'
os.environ['LUCIQ_ENABLE_BASIC_AI'] = 'true'
os.environ['LUCIQ_FAST_MODE'] = 'true'

print("üöÄ Starting Luciq API with Live AI Enhancement...")
print("üß† AI Enhancement Phase 23: Live Integration")
print("‚ö° Basic AI capabilities: ENABLED (using existing packages)")
print("üîí Advanced models: DISABLED (gradual approach)")
print("üìÅ Working directory:", os.getcwd())

try:
    # Import enhanced FastAPI app with basic AI
    from fastapi import FastAPI, HTTPException
    from fastapi.middleware.cors import CORSMiddleware
    from fastapi.responses import JSONResponse
    from pydantic import BaseModel
    from typing import Dict, Any, Optional
    import re
    import logging
    from datetime import datetime
    
    # Configure logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    # Create live enhanced FastAPI app
    app = FastAPI(
        title="Luciq API - Live Enhanced",
        description="Live Enhanced API with Basic AI Integration",
        version="2.6-live-enhanced"
    )
    
    # Add CORS middleware
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
    
    # Basic AI engine using existing packages (no external dependencies)
    class BasicSemanticEngine:
        """Basic semantic analysis using minimal dependencies"""
        
        def __init__(self):
            self.initialized = True
            logger.info("‚úÖ Basic Semantic Engine initialized")
            
        async def analyze_basic_semantics(self, content: str, context: Dict = None) -> Dict:
            """Basic semantic analysis using string processing and heuristics"""
            try:
                # Basic text analysis
                words = content.lower().split()
                word_count = len(words)
                char_count = len(content)
                sentence_count = len([s for s in content.split('.') if s.strip()])
                
                # Basic keyword extraction (top frequent words)
                word_freq = {}
                for word in words:
                    # Remove punctuation
                    clean_word = re.sub(r'[^\w]', '', word)
                    if len(clean_word) > 3:  # Filter short words
                        word_freq[clean_word] = word_freq.get(clean_word, 0) + 1
                
                top_keywords = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:5]
                
                # Basic sentiment analysis (improved heuristics)
                positive_words = [
                    'good', 'great', 'excellent', 'amazing', 'love', 'best', 'perfect',
                    'fantastic', 'wonderful', 'awesome', 'outstanding', 'brilliant',
                    'helpful', 'efficient', 'effective', 'valuable', 'useful', 'innovative'
                ]
                negative_words = [
                    'bad', 'terrible', 'awful', 'hate', 'worst', 'horrible', 'poor',
                    'disappointing', 'frustrating', 'useless', 'broken', 'slow',
                    'expensive', 'difficult', 'confusing', 'unreliable', 'problematic'
                ]
                
                content_lower = content.lower()
                positive_score = sum(1 for word in positive_words if word in content_lower)
                negative_score = sum(1 for word in negative_words if word in content_lower)
                
                # Calculate sentiment
                if positive_score > negative_score:
                    sentiment = "positive"
                    confidence = min((positive_score - negative_score) / max(word_count/10, 1), 1.0)
                elif negative_score > positive_score:
                    sentiment = "negative" 
                    confidence = min((negative_score - positive_score) / max(word_count/10, 1), 1.0)
                else:
                    sentiment = "neutral"
                    confidence = 0.5
                
                # Basic entity recognition (simple patterns)
                entities = []
                
                # Email pattern
                email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
                emails = re.findall(email_pattern, content)
                entities.extend([{'type': 'email', 'value': email} for email in emails])
                
                # URL pattern
                url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
                urls = re.findall(url_pattern, content)
                entities.extend([{'type': 'url', 'value': url} for url in urls])
                
                # Basic intent detection
                intent = "unknown"
                if any(word in content_lower for word in ['need', 'want', 'looking for', 'require']):
                    intent = "request"
                elif any(word in content_lower for word in ['how', 'what', 'when', 'where', 'why']):
                    intent = "question"
                elif any(word in content_lower for word in ['thank', 'thanks', 'appreciate']):
                    intent = "gratitude"
                elif any(word in content_lower for word in ['problem', 'issue', 'bug', 'error']):
                    intent = "complaint"
                
                # Business domain detection
                business_domains = {
                    'project_management': ['project', 'task', 'team', 'collaboration', 'deadline', 'management'],
                    'sales': ['sales', 'revenue', 'customer', 'lead', 'conversion', 'pipeline'],
                    'marketing': ['marketing', 'campaign', 'brand', 'advertising', 'promotion', 'social'],
                    'finance': ['finance', 'budget', 'cost', 'profit', 'investment', 'accounting'],
                    'technology': ['software', 'tech', 'api', 'database', 'cloud', 'integration']
                }
                
                detected_domains = []
                for domain, keywords in business_domains.items():
                    if any(keyword in content_lower for keyword in keywords):
                        detected_domains.append(domain)
                
                return {
                    "analysis_type": "basic_semantic_live_enhancement",
                    "text_metrics": {
                        "word_count": word_count,
                        "character_count": char_count,
                        "sentence_count": sentence_count,
                        "avg_word_length": sum(len(word) for word in words) / max(len(words), 1)
                    },
                    "sentiment_analysis": {
                        "sentiment": sentiment,
                        "confidence": round(confidence, 2),
                        "positive_indicators": positive_score,
                        "negative_indicators": negative_score
                    },
                    "keywords": [{"word": word, "frequency": freq} for word, freq in top_keywords],
                    "entities": entities,
                    "intent": intent,
                    "business_domains": detected_domains,
                    "context_analysis": context or {},
                    "ai_engine_status": "basic_live_enhancement",
                    "enhancement_level": "phase_23_incremental"
                }
                
            except Exception as e:
                logger.error(f"Basic semantic analysis error: {e}")
                return {
                    "analysis_type": "basic_semantic_error",
                    "error": str(e),
                    "ai_engine_status": "error_fallback"
                }
    
    # Initialize basic AI engine
    basic_ai_engine = None
    try:
        print("üß† Initializing Basic AI Engine (live enhancement)...")
        basic_ai_engine = BasicSemanticEngine()
        print("‚úÖ Basic AI Engine initialized successfully")
    except Exception as e:
        print(f"‚ö†Ô∏è Basic AI engine initialization failed: {e}")
        basic_ai_engine = None
    
    # Pydantic models
    class AnalysisRequest(BaseModel):
        content: str
        context: Optional[Dict[str, Any]] = {}
    
    class AnalysisResponse(BaseModel):
        success: bool
        engine_used: str
        processing_time_ms: float
        result: Dict[str, Any]
        timestamp: str
    
    # Basic endpoints (enhanced from minimal)
    @app.get("/")
    async def root():
        return {
            "message": "Luciq API - Live Enhanced Mode", 
            "status": "running",
            "ai_enhancement": "basic_semantic_enabled",
            "enhancement_type": "live_integration",
            "phase": "23_first_ai_integration"
        }
    
    @app.get("/health")
    async def health():
        return {
            "status": "healthy",
            "mode": "live_enhanced",
            "ai_engines": {
                "basic_semantic": "enabled" if basic_ai_engine else "failed",
                "advanced_models": "disabled_incremental_approach"
            },
            "dependencies": "minimal_packages_only",
            "phase": "23_ai_enhancement_live_integration",
            "enhancement_method": "live_deployment"
        }
    
    @app.get("/api/test")
    async def test():
        return {
            "backend": "operational",
            "containers": "docker",
            "frontend_port": 3001,
            "redis_port": 6379,
            "ai_enhancement": "basic_semantic_live_integrated",
            "enhancement_approach": "incremental_without_rebuild",
            "message": "Live enhanced backend with basic AI capabilities!"
        }
    
    # Live AI enhancement endpoint
    @app.post("/api/intelligence/basic", response_model=AnalysisResponse)
    async def basic_ai_analysis(request: AnalysisRequest):
        """
        Basic AI Analysis with live enhancement
        Uses minimal dependencies for immediate AI capabilities
        """
        start_time = datetime.now()
        
        try:
            if not basic_ai_engine:
                raise HTTPException(
                    status_code=503, 
                    detail="Basic AI engine not available"
                )
            
            logger.info(f"üß† Processing basic AI analysis: {request.content[:50]}...")
            
            # Perform basic AI analysis
            result = await basic_ai_engine.analyze_basic_semantics(
                request.content, 
                request.context
            )
            
            processing_time_ms = (datetime.now() - start_time).total_seconds() * 1000
            
            return AnalysisResponse(
                success=True,
                engine_used="basic_semantic_live",
                processing_time_ms=processing_time_ms,
                result=result,
                timestamp=datetime.now().isoformat()
            )
            
        except Exception as e:
            processing_time_ms = (datetime.now() - start_time).total_seconds() * 1000
            logger.error(f"‚ùå Basic AI analysis failed: {e}")
            
            return AnalysisResponse(
                success=False,
                engine_used="basic_semantic_live",
                processing_time_ms=processing_time_ms,
                result={"error": str(e)},
                timestamp=datetime.now().isoformat()
            )
    
    # System status endpoint (enhanced)
    @app.get("/api/system/status")
    async def system_status():
        """Live enhanced system status"""
        return {
            "system_status": "live_enhanced_operational",
            "api_mode": "live_enhanced_with_basic_ai",
            "containers": {
                "backend": "operational_live_enhanced",
                "frontend": "operational",
                "redis": "healthy"
            },
            "ai_engines": {
                "basic_semantic": "enabled" if basic_ai_engine else "failed",
                "advanced_models": "disabled_incremental_approach",
                "next_integration": "advanced_semantic_with_nlp_packages"
            },
            "enhancement_phase": "23_live_ai_integration",
            "enhancement_method": "live_deployment_without_rebuild",
            "stability": "maintained_through_incremental_live_enhancement",
            "packages_used": "minimal_existing_container_packages",
            "timestamp": datetime.now().isoformat()
        }
    
    # Enhanced statistics endpoint
    @app.get("/api/enhancement/stats")
    async def enhancement_stats():
        """Statistics about the live AI enhancement"""
        return {
            "enhancement_stats": {
                "type": "live_ai_integration",
                "phase": "23_first_ai_engine",
                "method": "incremental_without_rebuild",
                "ai_capabilities": "basic_semantic_analysis",
                "packages_added": "none_using_existing",
                "stability_maintained": True,
                "performance_impact": "minimal"
            },
            "ai_engine_capabilities": {
                "text_analysis": "enabled",
                "sentiment_analysis": "enabled",
                "keyword_extraction": "enabled",
                "entity_recognition": "basic",
                "intent_detection": "basic",
                "business_domain_detection": "enabled"
            },
            "next_enhancement_plan": {
                "next_engine": "advanced_semantic_with_nlp",
                "approach": "container_rebuild_with_nlp_packages",
                "estimated_improvement": "50x_more_sophisticated_analysis"
            },
            "timestamp": datetime.now().isoformat()
        }
    
    print("‚úÖ Live Enhanced FastAPI app created successfully")
    print("üß† Basic AI Engine: Ready for live testing")
    print("üåê Starting live enhanced server on 0.0.0.0:8003")
    print("üìñ API docs available at http://localhost:8003/docs")
    print("üß™ Test basic AI: POST /api/intelligence/basic")
    print("üìä Enhancement stats: GET /api/enhancement/stats")
    
    # Start server
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8003,
        reload=False,
        log_level="info",
        access_log=True
    )
    
except Exception as e:
    print(f"‚ùå Failed to start live enhanced API server: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1) 